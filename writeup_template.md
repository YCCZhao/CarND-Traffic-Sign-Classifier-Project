# Project Walkthrough
---
The steps of this project are the following:
* Load the data set
* Explore, summarize and visualize the data set
* Design, train and test a model architecture
* Use the model to make predictions on new images
* Analyze the softmax probabilities of the new images
* Summarize the results 
---

## Data Set Summary & Exploration

### 1.Basic Summary of the Data Set. 

I used the numpy library to calculate summary statistics of the traffic signs data set:

* The size of training set is 34799
* The size of the validation set is 4410
* The size of test set is 12630
* The shape of a traffic sign image is 32x32x3
* The number of unique classes/labels in the data set is 43

### 2. Exploratory Visualization of the Dataset.

Here is an exploratory visualization of the data set. 

First I sampled 25 images from the training set. I learned that it is hard to classify some of the images by human eyes. 

![sample][./examples/image_sample.png]

Then I explored the class distribution in each set. It is noted that class distribution is not uniform, meaning some classes
have more data. 

!distribution][./examples/class_distribution.png]

### 3. Design and Test a Model Architecture

#### 1. Preprocessed the image data. 

When exploring the dataset, it was noted that some classes have more dataset than other. This could lead to poor model. For example,
training dataset consists of 90% class 1 data, and 10% class 2 data. Model would always predict class 1, and it would yield a 90% 
accuracy. However it is not a good model for prediction. Therefore training data were balanced so that each class has similar number
of training dataset.

Now the class distribution looked like this:
![balance][./examples/after_balancing.png]

After obtaining even distributed training dataset. Data augmentation is performed. [Image Augmentation Library](https://github.com/aleju/imgaug) is used.

For each image in the balanced training set, 20 new images were generated: 
- 5 of them were sheared by -5 to 5 degrees, 
- 5 of them were translated in the x and/or y direction with 7 degrees, 
- 5 of them were scaled by -10 to +10 percent, 
- and rest of them were roated by -15 to 15 degrees.

These augmentation methods were used because images generated by them could still be recognized as traffic signs. flipped images or
images rotated by 90 degrees would not be good training examples, as traffic signs are rarely presented like that in real life.

The final training dataset has the size of 164367.
The next step is to convert RGB images to grayscale. In this way, the features were compressed while reserving important information.
Belows are the sample images after converting to grayscale
![balance][./examples/gray_scale]

Finally, images were normalized, so that the minimum, and maximum values of each dataset were 0, and 255.
Belows are them sample images after normalization.
![balance][./examples/normalization]


#### 2. Final model architecture description

Final model architecture was designed by mimicking VGGNet.
The architecture of VGGNet used developed for the Large Scale Visual Recognition Challenge is shown below
![VGGNet][./VGGNet.PNG][source](http://cs231n.stanford.edu/slides/2017/cs231n_2017_lecture9.pdf)

The detial architecture of model designed for this project is described in the table below:

|Layers|Properties|
|:-------|:-----------|
|conv| 6 3x3 filters with stride of 1; padding of size 1|
|relu| Activation|
|conv| 6 3x3 filters with stride of 1; padding of size 1|
|relu| Activation|
|conv| 6 3x3 filters with stride of 1; padding of size 1|
|relu| Activation|
|pool| Max Pooling, 2x2 filter with stride of 1; no padding| 
|conv| 16 3x3 filters with stride of 1; padding of size 1|
|relu| Activation|
|conv| 16 3x3 filters with stride of 1; padding of size 1|
|relu| Activation|
|conv| 16 3x3 filters with stride of 1; padding of size 1|
|relu| Activation|
|pool| Max Pooling, 2x2 filter with stride of 1; no padding| 
|fc| fully connected layers, output 256 hidden layers|
|relu| Activation|
|fc| fully connected layers, output 64 hidden layers|
|relu| Activation|
|classifier| 43 class classifier|


#### 3. Training. 
To train the model, I used backpropagation to find the gradient of model parameters. Mini-batch stochastic gradient descent is used
to find model parameters that yield the optimal perfomrance. batch size 128, learning rate of 0.001, and 10 epochs were used for 
training. To avoid overfitting 50% drop out rate was used.

```
EPOCHS = 10
BATCH_SIZE = 128
rate = 0.001
drop_out = 0.5
```

#### 4. Describe the approach taken for finding a solution and getting the validation set accuracy to be at least 0.93. 
The results on the training, validation and test sets of my final model were:
* training set accuracy of 99.8%
* validation set accuracy of 97%
* test set accuracy of 95.2%

VGGNet was chosen because it was relatively easy to implement while providing accurate predition. It showed a high accuracy in the 2014 
Large Scale Visual Recognition Challenge. Therefore I believed that it would also work very well on the traffic sign application. 
VGG was developed to classified images of 1000 different labels, therefore it has a very deep architecture. But traffic signs
share many similarities among themselves, so the traffic sign application wouldn't require as many layers and as many filters in each 
convolutional layer. My final model only included 6 convolutional layers. VGG nets were used, also because it required less parameters.
"Stack of three 3x3 conv (stride 1) layers has same effective receptive field as one 7x7 conv layer." Three 3x3 conv layer has less parameters to train than a 7x7 conv layer. Beside efficiency, three conv layers also provide more non-linearities, which helps to improve model accuracy.

Dropout was implemented to the model after finding training accuracy were consistantly around 5% higher than validation accuracy. I predicted that model was overfitted, so I added 50% dropout rate in the full connected layers. With dropout, validation accuracy was increased.

Two other architectures were designed and trained before VGGNet. They are LeNet and AlexNet. 
Training accuracies of LeNet stop improving around 93% with augmented data, so I concluded that a model with deeper layers are needed. 
AlexNet was selected to train. The first AlexNet(see table below) I trained yielded a similar accuracy as LeNet. To improve the accuracy, I decreased the filter size. Accuracy was not improved by doing so, therefore I tried increasing the filter depth instead. The third AlexNet yields a test accuracy around 95%, however it required to train more parameters than VGGNet. Thus VGGNet was chosen as final model instead.

See model description below:

**LeNet:**
![LeNet][./LeNet.PNG][source](http://cs231n.stanford.edu/slides/2017/cs231n_2017_lecture9.pdf)

**Architecture Summary**

|Layers| Properties |
|:-------|:-----------|
|conv| 6 5x5 filters with stride of 1; no padding
|relu| Activation
|pool| Max Pooling, 2x2 filter with stride of 1; no padding
|conv| 16 5x5 filters with stride of 1; no padding
|relu| Activation
|pool| Max Pooling, 2x2 filter with stride of 1; no padding
|fc| fully connected layers, output 120 hidden layers
|relu| Activation
|fc| fully connected layers, output 84 hidden layers
|relu| Activation
|classifier| 43 class classifier

**AlexNet**
![AlexNet][./AlexNet.PNG][source](http://cs231n.stanford.edu/slides/2017/cs231n_2017_lecture9.pdf)

**Architecture Summary**

|Layers|AlexNet_1 Properties|AlexNet_2 Properties|AlexNet_3 Properties|
|:-------|:-----------|:-------|:-----------|
|conv| 6 5x5 filters with stride of 1; no padding| 6 5x5 filters with stride of 1; padding of size 2| 16 5x5 filters with stride of 1; no padding|
|relu| Activation| Activation| Activation|
|pool| Max Pooling, 2x2 filter with stride of 1; no padding| Max Pooling, 2x2 filter with stride of 1; no padding| Max Pooling, 2x2 filter with stride of 1; no padding|
|conv| 16 5x5 filters with stride of 1; no padding| 16 5x5 filters with stride of 1; padding of size 2| 32 5x5 filters with stride of 1; no padding|
|relu| Activation| Activation| Activation|
|pool| Max Pooling, 2x2 filter with stride of 1; no padding| Max Pooling, 2x2 filter with stride of 1; no padding| Max Pooling, 2x2 filter with stride of 1; no padding|
|conv| 32 3x3 filters with stride of 1; padding of size 1| 32 3x3 filters with stride of 1; padding of size 1| 64 3x3 filters with stride of 1; padding of size 1|
|relu| Activation| Activation| Activation|
|conv| 32 3x3 filters with stride of 1; padding of size 1| 32 3x3 filters with stride of 1; padding of size 1| 64 3x3 filters with stride of 1; padding of size 1|
|relu| Activation| Activation| Activation|
|conv| 16 3x3 filters with stride of 1; padding of size 1| 16 3x3 filters with stride of 1; padding of size 1| 32 3x3 filters with stride of 1; padding of size 1|
|relu| Activation| Activation| Activation|
|fc| fully connected layers, output 120 hidden layers| fully connected layers, output 256 hidden layers| fully connected layers, output 200 hidden layers|
|relu| Activation| Activation| Activation|
|fc| fully connected layers, output 84 hidden layers| fully connected layers, output 128 hidden layers| fully connected layers, output 84 hidden layers|
|relu| Activation| Activation| Activation|
|classifier| 43 class classifier| 43 class classifier| 43 class classifier|

---
## Test a Model on New Images

### 1. Choose five German traffic signs found on the web and provide them in the report. 
Here are five German traffic signs that I found on the web:

![new_image1][./new_images/constrt]![new_image2][./new_images/ROW]![new_image3][./new_images/speed_limit_60]![new_image4][./new_images/stop]![new_image5][./new_images/yield]

### 2. Discuss the model's predictions on these new traffic signs and compare the results to predicting on the test set. 
At a minimum, discuss what the predictions were, the accuracy on these new predictions, and compare the accuracy to the accuracy on the test set 

Here are the results of the prediction:

| Image			        |     Prediction	        					| 
|:---------------------:|:---------------------------------------------:| 
| Right-of-way at the next intersection | Stop sign   									| 
| Road work | U-turn 										|
| Speed limit (60km/h) | Yield											|
| Stop | Bumpy Road					 				|
| Yield | Slippery Road      							|


The model was able to correctly guess 4 of the 5 traffic signs, which gives an accuracy of 80%. This compares favorably to the accuracy on the test set of ...

### 3. Describe how certain the model is when predicting on each of the five new images by looking at the softmax probabilities for each prediction. 
Provide the top 5 softmax probabilities for each image along with the sign type of each probability. 

The code for making predictions on my final model is located in the 11th cell of the Ipython notebook.

For the first image, the model is relatively sure that this is a stop sign (probability of 0.6), and the image does contain a stop sign. The top five soft max probabilities were

| Probability         	|     Prediction	        					| 
|:---------------------:|:---------------------------------------------:| 
| .60         			| Stop sign   									| 
| .20     				| U-turn 										|
| .05					| Yield											|
| .04	      			| Bumpy Road					 				|
| .01				    | Slippery Road      							|

For the second image ... 
